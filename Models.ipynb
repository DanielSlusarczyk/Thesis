{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b><span style='color:#2563eb'>00 | </span>Modele predykcji</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>Import bibliotek</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set auto reload after making changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Modeling\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Wrote myself\n",
    "from source.CustomPlot import CustomPlot\n",
    "from source.Utils import SplitDateColumn, AddPrefixToColumns, DescribeData\n",
    "from source.EvaluateModel import EvaluteModel\n",
    "\n",
    "# GPU or CPU use for model\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>Zbiory</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/'\n",
    "\n",
    "gas_prices = pd.read_csv(os.path.join(PATH, 'gas_prices.csv'),\n",
    "                   dtype={'lowest_price_per_mwh': 'float64',\n",
    "                          'highest_price_per_mwh': 'float64',\n",
    "                          'data_block_id': 'int64'},\n",
    "                   parse_dates=['forecast_date', 'origin_date'])\n",
    "\n",
    "electricity_prices = pd.read_csv(os.path.join(PATH, 'electricity_prices.csv'),\n",
    "                   dtype={'euros_per_mwh': 'float64',\n",
    "                          'data_block_id': 'int64'},\n",
    "                   parse_dates=['forecast_date', 'origin_date'])\n",
    "\n",
    "historical_weather = pd.read_csv(os.path.join(PATH, 'historical_weather.csv'),\n",
    "                dtype={'temperature': 'float64',\n",
    "                        'dewpoint': 'float64',\n",
    "                        'rain': 'float64',\n",
    "                        'snowfall': 'float64',\n",
    "                        'surface_pressure': 'float64',\n",
    "                        'cloudcover_total': 'int16',\n",
    "                        'cloudcover_low': 'int16',\n",
    "                        'cloudcover_mid': 'int16',\n",
    "                        'cloudcover_high': 'int16',\n",
    "                        'winddirection_10m': 'int16',\n",
    "                        'shortwave_radiation': 'float64',\n",
    "                        'direct_solar_radiation' : 'float64',\n",
    "                        'diffuse_radiation': 'float64',\n",
    "                        'latitude': 'float64',\n",
    "                        'longitude' : 'float64',\n",
    "                        'data_block_id' : 'int64'},\n",
    "\n",
    "                parse_dates=['datetime'])\n",
    "\n",
    "forecast_weather = pd.read_csv(os.path.join(PATH, 'forecast_weather.csv'),\n",
    "                dtype={'temperature': 'float64',\n",
    "                        'dewpoint': 'float64',\n",
    "                        'total_precipitation': 'float64',\n",
    "                        'snowfall': 'float64',\n",
    "                        'cloudcover_total': 'float64',\n",
    "                        'cloudcover_low': 'float64',\n",
    "                        'cloudcover_mid': 'float64',\n",
    "                        'cloudcover_high': 'float64',\n",
    "                        '10_metre_u_wind_component': 'float64',\n",
    "                        '10_metre_v_wind_component': 'float64',\n",
    "                        'direct_solar_radiation' : 'float64',\n",
    "                        'surface_solar_radiation_downwards': 'float64',\n",
    "                        'latitude': 'float64',\n",
    "                        'longitude' : 'float64',\n",
    "                        'data_block_id' : 'int64',\n",
    "                        'hours_ahead': 'int16'},\n",
    "\n",
    "                parse_dates=['origin_datetime', 'forecast_datetime'])\n",
    "\n",
    "train = pd.read_csv(os.path.join(PATH, 'train.csv'),\n",
    "                dtype={ 'county': 'int16',\n",
    "                        'is_business': 'boolean',\n",
    "                        'product_type': 'int8',\n",
    "                        'target': 'float64',\n",
    "                        'is_consumption': 'boolean',\n",
    "                        'data_block_id' : 'int64',\n",
    "                        'row_id' : 'int16',\n",
    "                        'prediction_unit_id' : 'int16' },\n",
    "\n",
    "                parse_dates=['datetime'])\n",
    "\n",
    "client = pd.read_csv(os.path.join(PATH, 'client.csv'),\n",
    "                dtype={ 'county': 'int16',\n",
    "                        'is_business': 'boolean',\n",
    "                        'product_type': 'int8',\n",
    "                        'eic_count': 'float64',\n",
    "                        'installed_capacity': 'float64',\n",
    "                        'data_block_id' : 'int64'},\n",
    "\n",
    "                parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station = pd.read_csv(os.path.join(PATH, 'weather_station_to_county_mapping.csv'),\n",
    "                   dtype={'county_name': 'str',\n",
    "                          'longitude': 'float64',\n",
    "                          'latitude': 'float64',\n",
    "                          'county': 'float64'})\n",
    "\n",
    "weather_station.dropna(subset='county', inplace=True)\n",
    "weather_station.drop(columns=['county_name'], inplace=True)\n",
    "weather_station['county'] = weather_station['county'].astype('int')\n",
    "weather_station[['latitude', 'longitude']] = weather_station[['latitude', 'longitude']].astype(float).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>Scelenie zbiorÃ³w</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.Utils import SplitDateColumn, AddPrefixToColumns\n",
    "\n",
    "class FeaturesProcessing():\n",
    "    def __init__(self,\n",
    "            train: pd.DataFrame,\n",
    "            client: pd.DataFrame,\n",
    "            gas_prices: pd.DataFrame,\n",
    "            forecast_weather: pd.DataFrame,\n",
    "            electricity_prices: pd.DataFrame,\n",
    "            weather_station: pd.DataFrame):\n",
    "        \n",
    "        self.train = train\n",
    "        self.weather_station = weather_station\n",
    "\n",
    "        self.client = self.__prepareClient(client)\n",
    "        self.gas_prices = self.__prepareGasPrices(gas_prices)\n",
    "        self.forecast_weather = self.__prepareForecastData(forecast_weather)\n",
    "        self.electricity_prices = self.__prepareEnergyPrices(electricity_prices)\n",
    "\n",
    "        self.data = train.copy()\n",
    "        self.__merge('gas prices', self.gas_prices, on=['data_block_id'])\n",
    "        self.__merge('electricity prices', self.electricity_prices, on=['datetime', 'data_block_id'])\n",
    "        self.__merge('client', self.client, on=['county', 'is_business', 'product_type', 'data_block_id'])\n",
    "        self.__merge('forecast weather', self.forecast_weather, on=['datetime', 'county', 'data_block_id'])\n",
    "        \n",
    "        self.__AddCustomFeatures()\n",
    "\n",
    "        SplitDateColumn(self.data, 'datetime')\n",
    "\n",
    "    def getData(self, dropNa = False):\n",
    "        if dropNa:\n",
    "            return self.data.dropna()\n",
    "        \n",
    "        return self.data\n",
    "\n",
    "    def __merge(self, datasetName: str, data: pd.DataFrame, on=[], how='left') -> pd.DataFrame:\n",
    "        print(f'MERGING: <- {datasetName}')\n",
    "        print(f'- Before: <- {len(self.data)} rows')\n",
    "\n",
    "        self.data = self.data.merge(data, how=how, on=on)\n",
    "        print(f'- After: {len(self.data)} rows')\n",
    "        print()\n",
    "\n",
    "    def __prepareClient(self, client: pd.DataFrame) -> pd.DataFrame:\n",
    "        client = client.drop(columns=['date'])\n",
    "\n",
    "        return client\n",
    "\n",
    "    def __prepareForecastData(self, forecast_weather: pd.DataFrame) -> pd.DataFrame:\n",
    "        forecast_weather = forecast_weather.rename(columns = {'forecast_datetime': 'datetime'})\n",
    "        forecast_weather.drop(columns = 'origin_datetime', inplace=True)\n",
    "        forecast_weather['datetime'] = forecast_weather['datetime'].dt.tz_convert('Europe/Brussels').dt.tz_localize(None)\n",
    "\n",
    "        # Map to weather locations\n",
    "        forecast_weather[['latitude', 'longitude']] = forecast_weather[['latitude', 'longitude']].astype(float).round(1)\n",
    "        forecast_weather = forecast_weather.merge(self.weather_station, how='left', on=['latitude', 'longitude'])\n",
    "\n",
    "        # Some weather locations are outside any county\n",
    "        forecast_weather.dropna(subset='county', inplace=True)\n",
    "\n",
    "        forecast_weather['county'] = forecast_weather['county'].astype(int)\n",
    "\n",
    "        # Some county have many weather locations\n",
    "        forecast_weather = forecast_weather.groupby(by=['datetime', 'county', 'data_block_id']).mean().reset_index()\n",
    "        \n",
    "        return forecast_weather\n",
    "\n",
    "    def __prepareEnergyPrices(self, electricity_prices: pd.DataFrame) -> pd.DataFrame:\n",
    "        columns = ['euros_per_mwh', 'data_block_id']\n",
    "\n",
    "        ep = electricity_prices[columns].copy()\n",
    "        ep['datetime'] = electricity_prices['forecast_date'] + timedelta(days=1)\n",
    "\n",
    "        AddPrefixToColumns(ep, ['euros_per_mwh'], 'elec_price_')\n",
    "\n",
    "        return ep\n",
    "    \n",
    "    def __prepareGasPrices(self, gas_prices: pd.DataFrame) -> pd.DataFrame:\n",
    "        columns = ['highest_price_per_mwh', 'lowest_price_per_mwh', 'data_block_id']\n",
    "\n",
    "        gp = gas_prices[columns].copy()\n",
    "\n",
    "        AddPrefixToColumns(gp, ['highest_price_per_mwh', 'lowest_price_per_mwh'], 'gas_')\n",
    "        \n",
    "        return gp\n",
    "    \n",
    "    def __AddCustomFeatures(self):\n",
    "        merge = ['county', 'is_business', 'product_type', 'data_block_id', 'is_consumption', 'datetime']\n",
    "\n",
    "        feature = 'target_week_ago'\n",
    "        trainMinus7 = self.train.copy()\n",
    "        trainMinus7['datetime'] = trainMinus7['datetime'] + timedelta(days=7)\n",
    "        trainMinus7['data_block_id'] = trainMinus7['data_block_id'] + 7\n",
    "        trainMinus7.rename(columns={'target' : feature}, inplace=True)\n",
    "\n",
    "        self.data = self.data.merge(trainMinus7[merge + [feature]], how='left', on=merge)\n",
    "\n",
    "        feature = 'target_3_days_ago'\n",
    "        trainMinus3 = self.train.copy()\n",
    "        trainMinus3['datetime'] = trainMinus3['datetime'] + timedelta(days=3)\n",
    "        trainMinus3['data_block_id'] = trainMinus3['data_block_id'] + 3\n",
    "        trainMinus3.rename(columns={'target' : feature}, inplace=True)\n",
    "\n",
    "        self.data = self.data.merge(trainMinus3[merge + [feature]], how='left', on=merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = FeaturesProcessing(\n",
    "    train=train,\n",
    "    client= client,\n",
    "    gas_prices=gas_prices,\n",
    "    forecast_weather=forecast_weather,\n",
    "    electricity_prices=electricity_prices,\n",
    "    weather_station=weather_station\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DescribeData(fp.getData())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>PodziaÅ‚ na zbiory do modelÃ³w</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'is_business',\n",
    "    'product_type',\n",
    "    'is_consumption',\n",
    "    'county',\n",
    "    'temperature',\n",
    "    'dewpoint',\n",
    "    'cloudcover_high',\n",
    "    'cloudcover_low',\n",
    "    'cloudcover_mid',\n",
    "    'cloudcover_total',\n",
    "    '10_metre_u_wind_component',\n",
    "    '10_metre_v_wind_component',\n",
    "    'direct_solar_radiation',\n",
    "    'surface_solar_radiation_downwards',\n",
    "    'snowfall',\n",
    "    'total_precipitation',\n",
    "    'installed_capacity',\n",
    "    'elec_price_euros_per_mwh',\n",
    "    'datetime_hour',\n",
    "    'gas_highest_price_per_mwh',\n",
    "    'gas_lowest_price_per_mwh',\n",
    "    'target_week_ago',\n",
    "    'target_3_days_ago'\n",
    "    ]\n",
    "target_columns = ['target']\n",
    "\n",
    "mergedData = fp.getData(dropNa=True)\n",
    "\n",
    "X = mergedData[features]\n",
    "y = mergedData[target_columns]\n",
    "\n",
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Ocena modelu</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_name = json.load(open(os.path.join(PATH, 'county_id_to_name_map.json')))\n",
    "county_name = {int(k):str(v) for k,v in county_name.items()}\n",
    "\n",
    "modelEvaluator = EvaluteModel(X_test, y_test, mergedData, features, county_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>XGBoost</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBRegressor (\n",
    "    # Device ordinal, available options are cpu, cuda, and gpu.\n",
    "    device = device, \n",
    "    enable_categorical=True,\n",
    "    # Number of gradient boosted trees\n",
    "    n_estimators = 1000,\n",
    "    # Step size shrinkage used in update to prevents overfitting\n",
    "    eta=0.1,\n",
    "    # Activates early stopping. Validation metric needs to improve at least once in every early_stopping_rounds round(s) to continue training\n",
    "    early_stopping_rounds=100,\n",
    "    # L2 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_lambda = 1,\n",
    "    # L1 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_alpha = 0,\n",
    "    # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    gamma = 0,\n",
    "    # Specify the learning task and the corresponding learning objective\n",
    "    objective = 'reg:absoluteerror'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Uczenie</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvaluator.test(clf, random_day=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Wyniki</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'name': clf.feature_names_in_, 'importance': clf.feature_importances_}).sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>Las losowy</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(max_depth=10, n_estimators=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Uczenie</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Wyniki</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "np.sqrt(MSE(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>Szukanie hiperparametrÃ³w</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor (\n",
    "    # Device ordinal, available options are cpu, cuda, and gpu.\n",
    "    device = device, \n",
    "    enable_categorical=True,\n",
    "    # Number of gradient boosted trees\n",
    "    n_estimators = 1000,\n",
    "    # Step size shrinkage used in update to prevents overfitting\n",
    "    eta=0.1,\n",
    "    # Activates early stopping. Validation metric needs to improve at least once in every early_stopping_rounds round(s) to continue training\n",
    "    early_stopping_rounds=100,\n",
    "    # L2 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_lambda = 1,\n",
    "    # L1 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_alpha = 0,\n",
    "    # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    gamma = 0,\n",
    " )\n",
    "\n",
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'n_estimators': [1000],\n",
    "        'eta': [0.1, 0.3, 0.5],\n",
    "        'reg_lambda': [0.5, 1, 2],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = GridSearchCV(model, params, verbose=2)\n",
    "\n",
    "#clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>ZaÅ‚Ä…czanie odpowiedzi</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enefit\n",
    "env = enefit.make_env()\n",
    "iter_test = env.iter_test()\n",
    "\n",
    "for (test, revealed_targets, client, historical_weather,\n",
    "        forecast_weather, electricity_prices, gas_prices, sample_prediction) in iter_test:\n",
    "\n",
    "      data = FeaturesProcessing(\n",
    "              train = test,\n",
    "              client = client,\n",
    "              forecast_weather = forecast_weather,\n",
    "              gas_prices = gas_prices,\n",
    "              electricity_prices = electricity_prices,\n",
    "              weather_station = weather_station).getData()\n",
    "\n",
    "      sample_prediction['target'] = clf.predict(data)\n",
    "      env.predict(sample_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
