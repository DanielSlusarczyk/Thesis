{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b><span style='color:#2563eb'>00 | </span>Modele predykcji</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>Import bibliotek</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set auto reload after making changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Modeling\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Wrote myself\n",
    "from source.CustomPlot import CustomPlot\n",
    "from source.Utils import SplitDateColumn, AddPrefixToColumns, DescribeData\n",
    "from source.EvaluateModel import EvaluteModel\n",
    "\n",
    "# GPU or CPU use for model\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>Zbiory</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/'\n",
    "\n",
    "gas_prices = pd.read_csv(os.path.join(PATH, 'gas_prices.csv'),\n",
    "                   dtype={'lowest_price_per_mwh': 'float64',\n",
    "                          'highest_price_per_mwh': 'float64',\n",
    "                          'data_block_id': 'int64'},\n",
    "                   parse_dates=['forecast_date', 'origin_date'])\n",
    "\n",
    "electricity_prices = pd.read_csv(os.path.join(PATH, 'electricity_prices.csv'),\n",
    "                   dtype={'euros_per_mwh': 'float64',\n",
    "                          'data_block_id': 'int64'},\n",
    "                   parse_dates=['forecast_date', 'origin_date'])\n",
    "\n",
    "historical_weather = pd.read_csv(os.path.join(PATH, 'historical_weather.csv'),\n",
    "                dtype={'temperature': 'float64',\n",
    "                        'dewpoint': 'float64',\n",
    "                        'rain': 'float64',\n",
    "                        'snowfall': 'float64',\n",
    "                        'surface_pressure': 'float64',\n",
    "                        'cloudcover_total': 'int16',\n",
    "                        'cloudcover_low': 'int16',\n",
    "                        'cloudcover_mid': 'int16',\n",
    "                        'cloudcover_high': 'int16',\n",
    "                        'winddirection_10m': 'int16',\n",
    "                        'shortwave_radiation': 'float64',\n",
    "                        'direct_solar_radiation' : 'float64',\n",
    "                        'diffuse_radiation': 'float64',\n",
    "                        'latitude': 'float64',\n",
    "                        'longitude' : 'float64',\n",
    "                        'data_block_id' : 'int64'},\n",
    "\n",
    "                parse_dates=['datetime'])\n",
    "\n",
    "forecast_weather = pd.read_csv(os.path.join(PATH, 'forecast_weather.csv'),\n",
    "                dtype={'temperature': 'float64',\n",
    "                        'dewpoint': 'float64',\n",
    "                        'total_precipitation': 'float64',\n",
    "                        'snowfall': 'float64',\n",
    "                        'cloudcover_total': 'float64',\n",
    "                        'cloudcover_low': 'float64',\n",
    "                        'cloudcover_mid': 'float64',\n",
    "                        'cloudcover_high': 'float64',\n",
    "                        '10_metre_u_wind_component': 'float64',\n",
    "                        '10_metre_v_wind_component': 'float64',\n",
    "                        'direct_solar_radiation' : 'float64',\n",
    "                        'surface_solar_radiation_downwards': 'float64',\n",
    "                        'latitude': 'float64',\n",
    "                        'longitude' : 'float64',\n",
    "                        'data_block_id' : 'int64',\n",
    "                        'hours_ahead': 'int16'},\n",
    "\n",
    "                parse_dates=['origin_datetime', 'forecast_datetime'])\n",
    "\n",
    "train = pd.read_csv(os.path.join(PATH, 'train.csv'),\n",
    "                dtype={ 'county': 'int16',\n",
    "                        'is_business': 'boolean',\n",
    "                        'product_type': 'int8',\n",
    "                        'target': 'float64',\n",
    "                        'is_consumption': 'boolean',\n",
    "                        'data_block_id' : 'int64',\n",
    "                        'row_id' : 'int16',\n",
    "                        'prediction_unit_id' : 'int16' },\n",
    "\n",
    "                parse_dates=['datetime'])\n",
    "\n",
    "client = pd.read_csv(os.path.join(PATH, 'client.csv'),\n",
    "                dtype={ 'county': 'int16',\n",
    "                        'is_business': 'boolean',\n",
    "                        'product_type': 'int8',\n",
    "                        'eic_count': 'float64',\n",
    "                        'installed_capacity': 'float64',\n",
    "                        'data_block_id' : 'int64'},\n",
    "\n",
    "                parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station = pd.read_csv(os.path.join(PATH, 'weather_station_to_county_mapping.csv'),\n",
    "                   dtype={'county_name': 'str',\n",
    "                          'longitude': 'float64',\n",
    "                          'latitude': 'float64',\n",
    "                          'county': 'float64'})\n",
    "\n",
    "weather_station.dropna(subset='county', inplace=True)\n",
    "weather_station.drop(columns=['county_name'], inplace=True)\n",
    "weather_station['county'] = weather_station['county'].astype('int')\n",
    "weather_station[['latitude', 'longitude']] = weather_station[['latitude', 'longitude']].astype(float).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>Scelenie zbiorÃ³w</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.Utils import SplitDateColumn, AddPrefixToColumns, IsEstionianHoliday, IsWeekend\n",
    "\n",
    "class FeaturesProcessing():\n",
    "    def __init__(self,\n",
    "            train: pd.DataFrame,\n",
    "            client: pd.DataFrame,\n",
    "            gas_prices: pd.DataFrame,\n",
    "            forecast_weather: pd.DataFrame,\n",
    "            electricity_prices: pd.DataFrame,\n",
    "            weather_station: pd.DataFrame,\n",
    "            submission=False):\n",
    "        \n",
    "        self.train = train\n",
    "        self.weather_station = weather_station\n",
    "\n",
    "        self.client = self.__prepareClient(client)\n",
    "        self.gas_prices = self.__prepareGasPrices(gas_prices)\n",
    "        self.forecast_weather = self.__prepareForecastData(forecast_weather)\n",
    "        self.electricity_prices = self.__prepareEnergyPrices(electricity_prices)\n",
    "\n",
    "        self.data = train.copy()\n",
    "        self.__merge('gas prices', self.gas_prices, on=['data_block_id'])\n",
    "        self.__merge('electricity prices', self.electricity_prices, on=['datetime', 'data_block_id'])\n",
    "        self.__merge('client', self.client, on=['county', 'is_business', 'product_type', 'data_block_id'])\n",
    "        self.__merge('forecast weather', self.forecast_weather, on=['datetime', 'county', 'data_block_id'])\n",
    "        \n",
    "        SplitDateColumn(self.data, 'datetime')\n",
    "        \n",
    "        # Using submission API requires AddRevealtedTargets method instead\n",
    "        if not submission:\n",
    "            self.__AddCustomFeatures(self.train)\n",
    "\n",
    "\n",
    "    def getData(self, dropNa = False):\n",
    "        if dropNa:\n",
    "            return self.data.dropna()\n",
    "        \n",
    "        return self.data\n",
    "\n",
    "    def __merge(self, datasetName: str, data: pd.DataFrame, on=[], how='left') -> pd.DataFrame:\n",
    "        print(f'MERGING: <- {datasetName}')\n",
    "        print(f'- Before: <- {len(self.data)} rows')\n",
    "\n",
    "        self.data = self.data.merge(data, how=how, on=on)\n",
    "        print(f'- After: {len(self.data)} rows')\n",
    "        print()\n",
    "\n",
    "    def __prepareClient(self, client: pd.DataFrame) -> pd.DataFrame:\n",
    "        client = client.drop(columns=['date'])\n",
    "\n",
    "        return client\n",
    "\n",
    "    def __prepareForecastData(self, forecast_weather: pd.DataFrame) -> pd.DataFrame:\n",
    "        forecast_weather = forecast_weather.rename(columns = {'forecast_datetime': 'datetime'})\n",
    "        forecast_weather.drop(columns = 'origin_datetime', inplace=True)\n",
    "        forecast_weather['datetime'] = forecast_weather['datetime'].dt.tz_localize(None)\n",
    "\n",
    "        # Map to weather locations\n",
    "        forecast_weather[['latitude', 'longitude']] = forecast_weather[['latitude', 'longitude']].astype(float).round(1)\n",
    "        forecast_weather = forecast_weather.merge(self.weather_station, how='left', on=['latitude', 'longitude'])\n",
    "\n",
    "        # Some weather locations are outside any county\n",
    "        forecast_weather.dropna(subset='county', inplace=True)\n",
    "\n",
    "        forecast_weather['county'] = forecast_weather['county'].astype(int)\n",
    "\n",
    "        # Some county have many weather locations\n",
    "        forecast_weather = forecast_weather.groupby(by=['datetime', 'county', 'data_block_id']).mean().reset_index()\n",
    "        \n",
    "        return forecast_weather\n",
    "\n",
    "    def __prepareEnergyPrices(self, electricity_prices: pd.DataFrame) -> pd.DataFrame:\n",
    "        columns = ['euros_per_mwh', 'data_block_id']\n",
    "\n",
    "        ep = electricity_prices[columns].copy()\n",
    "        ep['datetime'] = electricity_prices['forecast_date'] + timedelta(days=1)\n",
    "\n",
    "        AddPrefixToColumns(ep, ['euros_per_mwh'], 'elec_price_')\n",
    "\n",
    "        return ep\n",
    "    \n",
    "    def __prepareGasPrices(self, gas_prices: pd.DataFrame) -> pd.DataFrame:\n",
    "        columns = ['highest_price_per_mwh', 'lowest_price_per_mwh', 'data_block_id']\n",
    "\n",
    "        gp = gas_prices[columns].copy()\n",
    "\n",
    "        AddPrefixToColumns(gp, ['highest_price_per_mwh', 'lowest_price_per_mwh'], 'gas_')\n",
    "        \n",
    "        return gp\n",
    "    \n",
    "    def __AddLagFeature(self, source: pd.DataFrame, lag: int):\n",
    "        merge = ['county', 'is_business', 'product_type', 'is_consumption', 'datetime']\n",
    "\n",
    "        feature = f'target_{lag}_days_ago'\n",
    "        lag_data = source[merge + ['target']].copy()\n",
    "        lag_data['datetime'] += timedelta(days=lag)\n",
    "        lag_data.rename(columns={'target' : feature}, inplace=True)\n",
    "\n",
    "        self.data = self.data.merge(lag_data, how='left', on=merge)\n",
    "        print(f'New feature: {feature}')\n",
    "\n",
    "    \n",
    "    def __AddCustomFeatures(self, source: pd.DataFrame):\n",
    "\n",
    "        for lag in range(2, 15):\n",
    "            self.__AddLagFeature(source, lag)\n",
    "\n",
    "        self.data['is_holiday'] = self.data['datetime_date'].apply(IsEstionianHoliday)\n",
    "        print(f'New feature: is_holiday')\n",
    "        self.data['is_weekend'] = self.data['datetime_date'].apply(IsWeekend)\n",
    "        print(f'New feature: is_weekend')\n",
    "\n",
    "        self.data['datetime_hour_sin'] = np.sin(2 * np.pi * self.data['datetime_hour']/24.0)\n",
    "        print(f'New feature: datetime_hour_sin')\n",
    "        self.data['datetime_hour_cos'] = np.cos(2 * np.pi * self.data['datetime_hour']/24.0)\n",
    "        print(f'New feature: datetime_hour_cos')\n",
    "\n",
    "    def AddRevealtedTargets(self, targets: pd.DataFrame):\n",
    "        self.__AddCustomFeatures(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = FeaturesProcessing(\n",
    "    train=train,\n",
    "    client= client,\n",
    "    gas_prices=gas_prices,\n",
    "    forecast_weather=forecast_weather,\n",
    "    electricity_prices=electricity_prices,\n",
    "    weather_station=weather_station\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DescribeData(fp.getData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.getData().columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>PodziaÅ‚ na zbiory do modelÃ³w</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataset(features, data, data_block_id_splitter = 630, data_splitter = None):\n",
    "    target_column = ['target']\n",
    "\n",
    "    if data_splitter is not None:\n",
    "        train = data[data.datetime <= data_splitter]\n",
    "        test = data[data.datetime > data_splitter]\n",
    "    else:\n",
    "        train = data[data.data_block_id <= data_block_id_splitter]\n",
    "        test = data[data.data_block_id > data_block_id_splitter]\n",
    "\n",
    "    X_train = train[features]\n",
    "    X_test = test[features]\n",
    "\n",
    "    y_train = train[target_column]\n",
    "    y_test = test[target_column]\n",
    "\n",
    "    # For plot purposes\n",
    "    X_validation = test[features + ['datetime_date', 'datetime']]\n",
    "    return [X_train, X_test, y_train, y_test, X_validation]\n",
    "\n",
    "county_name = json.load(open(os.path.join(PATH, 'county_id_to_name_map.json')))\n",
    "\n",
    "county_name = {int(k):str(v) for k,v in county_name.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b><span style='color:#2563eb'>01 | </span>Badania modeli</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>Test - XGBoost (Zmienne endogeniczne)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Zmienne</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'is_business',\n",
    "    'product_type',\n",
    "    'is_consumption',\n",
    "    'county',\n",
    "    'temperature',\n",
    "    'dewpoint',\n",
    "    'cloudcover_high',\n",
    "    'cloudcover_low',\n",
    "    'cloudcover_mid',\n",
    "    'cloudcover_total',\n",
    "    '10_metre_u_wind_component',\n",
    "    '10_metre_v_wind_component',\n",
    "    'direct_solar_radiation',\n",
    "    'surface_solar_radiation_downwards',\n",
    "    'snowfall',\n",
    "    'total_precipitation',\n",
    "    'installed_capacity',\n",
    "    'elec_price_euros_per_mwh',\n",
    "    'datetime_hour',\n",
    "    'gas_highest_price_per_mwh',\n",
    "    'gas_lowest_price_per_mwh',\n",
    "    ]\n",
    "target_columns = ['target']\n",
    "\n",
    "mergedData = fp.getData(dropNa=True)\n",
    "\n",
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test, X_validation = prepareDataset(features, mergedData)\n",
    "modelEvaluator = EvaluteModel(X_test, y_test, X_validation, county_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Uczenie</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBRegressor (\n",
    "    # Device ordinal, available options are cpu, cuda, and gpu.\n",
    "    device = device, \n",
    "    enable_categorical=True,\n",
    "    # Number of gradient boosted trees\n",
    "    n_estimators = 1000,\n",
    "    # Step size shrinkage used in update to prevents overfitting\n",
    "    eta=0.1,\n",
    "    # Activates early stopping. Validation metric needs to improve at least once in every early_stopping_rounds round(s) to continue training\n",
    "    early_stopping_rounds=100,\n",
    "    # L2 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_lambda = 1,\n",
    "    # L1 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_alpha = 0,\n",
    "    # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    gamma = 0,\n",
    "    # Specify the learning task and the corresponding learning objective\n",
    "    objective = 'reg:absoluteerror'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Wyniki</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvaluator.test(clf, random_day=date(2023, 5, 27))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>Test - XGBoost (Zmienne egzogeniczne i endogeniczne)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Zmienne</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'is_business',\n",
    "    'product_type',\n",
    "    'is_consumption',\n",
    "    'county',\n",
    "    'temperature',\n",
    "    'dewpoint',\n",
    "    'cloudcover_high',\n",
    "    'cloudcover_low',\n",
    "    'cloudcover_mid',\n",
    "    'cloudcover_total',\n",
    "    '10_metre_u_wind_component',\n",
    "    '10_metre_v_wind_component',\n",
    "    'direct_solar_radiation',\n",
    "    'surface_solar_radiation_downwards',\n",
    "    'snowfall',\n",
    "    'total_precipitation',\n",
    "    'installed_capacity',\n",
    "    'elec_price_euros_per_mwh',\n",
    "    'datetime_hour',\n",
    "    'gas_highest_price_per_mwh',\n",
    "    'gas_lowest_price_per_mwh',\n",
    "    'target_2_days_ago',\n",
    "    'target_3_days_ago',\n",
    "    'target_4_days_ago',\n",
    "    'target_5_days_ago',\n",
    "    'target_6_days_ago',\n",
    "    'target_7_days_ago',\n",
    "    'target_8_days_ago',\n",
    "    'target_9_days_ago',\n",
    "    'target_10_days_ago',\n",
    "    'target_11_days_ago',\n",
    "    'target_12_days_ago',\n",
    "    'target_13_days_ago',\n",
    "    'target_14_days_ago',\n",
    "    ]\n",
    "target_columns = ['target']\n",
    "\n",
    "mergedData = fp.getData(dropNa=True)\n",
    "\n",
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test, X_validation = prepareDataset(features, mergedData)\n",
    "modelEvaluator = EvaluteModel(X_test, y_test, X_validation, county_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Uczenie</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBRegressor (\n",
    "    # Device ordinal, available options are cpu, cuda, and gpu.\n",
    "    device = device, \n",
    "    enable_categorical=True,\n",
    "    # Number of gradient boosted trees\n",
    "    n_estimators = 1000,\n",
    "    # Step size shrinkage used in update to prevents overfitting\n",
    "    eta=0.1,\n",
    "    # Activates early stopping. Validation metric needs to improve at least once in every early_stopping_rounds round(s) to continue training\n",
    "    early_stopping_rounds=100,\n",
    "    # L2 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_lambda = 1,\n",
    "    # L1 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_alpha = 0,\n",
    "    # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    gamma = 0,\n",
    "    # Specify the learning task and the corresponding learning objective\n",
    "    objective = 'reg:absoluteerror'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Wyniki</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvaluator.test(clf, random_day=date(2023, 5, 27))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model nie radzi sobie z predykcjÄ… dni wolnych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>Test 2 - XGBoost (Zmienne egzogeniczne i endogeniczne + dni wolne)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Zmienne</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.Utils import IsEstionianHoliday\n",
    "\n",
    "features = [\n",
    "    'is_business',\n",
    "    'product_type',\n",
    "    'is_consumption',\n",
    "    'county',\n",
    "    'temperature',\n",
    "    'dewpoint',\n",
    "    'cloudcover_high',\n",
    "    'cloudcover_low',\n",
    "    'cloudcover_mid',\n",
    "    'cloudcover_total',\n",
    "    '10_metre_u_wind_component',\n",
    "    '10_metre_v_wind_component',\n",
    "    'direct_solar_radiation',\n",
    "    'surface_solar_radiation_downwards',\n",
    "    'snowfall',\n",
    "    'total_precipitation',\n",
    "    'installed_capacity',\n",
    "    'elec_price_euros_per_mwh',\n",
    "    'datetime_hour',\n",
    "    'gas_highest_price_per_mwh',\n",
    "    'gas_lowest_price_per_mwh',\n",
    "    'target_2_days_ago',\n",
    "    'target_3_days_ago',\n",
    "    'target_4_days_ago',\n",
    "    'target_5_days_ago',\n",
    "    'target_6_days_ago',\n",
    "    'target_7_days_ago',\n",
    "    'target_8_days_ago',\n",
    "    'target_9_days_ago',\n",
    "    'target_10_days_ago',\n",
    "    'target_11_days_ago',\n",
    "    'target_12_days_ago',\n",
    "    'target_13_days_ago',\n",
    "    'target_14_days_ago',\n",
    "    'is_holiday',\n",
    "    ]\n",
    "target_columns = ['target']\n",
    "\n",
    "mergedData = pd.DataFrame(fp.getData(dropNa=True))\n",
    "mergedData['is_holiday'] = mergedData['datetime_date'].apply(IsEstionianHoliday)\n",
    "\n",
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test, X_validation = prepareDataset(features, mergedData)\n",
    "modelEvaluator = EvaluteModel(X_test, y_test, X_validation, county_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Uczenie</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBRegressor (\n",
    "    # Device ordinal, available options are cpu, cuda, and gpu.\n",
    "    device = device, \n",
    "    enable_categorical=True,\n",
    "    # Number of gradient boosted trees\n",
    "    n_estimators = 1000,\n",
    "    # Step size shrinkage used in update to prevents overfitting\n",
    "    eta=0.1,\n",
    "    # Activates early stopping. Validation metric needs to improve at least once in every early_stopping_rounds round(s) to continue training\n",
    "    early_stopping_rounds=100,\n",
    "    # L2 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_lambda = 1,\n",
    "    # L1 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_alpha = 0,\n",
    "    # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    gamma = 0,\n",
    "    # Specify the learning task and the corresponding learning objective\n",
    "    objective = 'reg:absoluteerror'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Wyniki</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvaluator.test(clf, random_day=date(2023, 5, 27))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>Test - XGBoost (Zmienne egzogeniczne/endogeniczne + dni wolne + cyklicznoÅ›Ä‡)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Zmienne</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.Utils import IsEstionianHoliday\n",
    "\n",
    "features = [\n",
    "    'is_business',\n",
    "    'product_type',\n",
    "    'is_consumption',\n",
    "    'county',\n",
    "    'temperature',\n",
    "    'dewpoint',\n",
    "    'cloudcover_high',\n",
    "    'cloudcover_low',\n",
    "    'cloudcover_mid',\n",
    "    'cloudcover_total',\n",
    "    '10_metre_u_wind_component',\n",
    "    '10_metre_v_wind_component',\n",
    "    'direct_solar_radiation',\n",
    "    'surface_solar_radiation_downwards',\n",
    "    'snowfall',\n",
    "    'total_precipitation',\n",
    "    'installed_capacity',\n",
    "    'elec_price_euros_per_mwh',\n",
    "    'gas_highest_price_per_mwh',\n",
    "    'gas_lowest_price_per_mwh',\n",
    "    'target_2_days_ago',\n",
    "    'target_3_days_ago',\n",
    "    'target_4_days_ago',\n",
    "    'target_5_days_ago',\n",
    "    'target_6_days_ago',\n",
    "    'target_7_days_ago',\n",
    "    'target_8_days_ago',\n",
    "    'target_9_days_ago',\n",
    "    'target_10_days_ago',\n",
    "    'target_11_days_ago',\n",
    "    'target_12_days_ago',\n",
    "    'target_13_days_ago',\n",
    "    'target_14_days_ago',\n",
    "    'is_holiday',\n",
    "    'datetime_hour_sin',\n",
    "    'datetime_hour_cos'\n",
    "    ]\n",
    "target_columns = ['target']\n",
    "\n",
    "mergedData = pd.DataFrame(fp.getData(dropNa=True))\n",
    "\n",
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test, X_validation = prepareDataset(features, mergedData)\n",
    "modelEvaluator = EvaluteModel(X_test, y_test, X_validation, county_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Uczenie</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBRegressor (\n",
    "    # Device ordinal, available options are cpu, cuda, and gpu.\n",
    "    device = device, \n",
    "    enable_categorical=True,\n",
    "    # Number of gradient boosted trees\n",
    "    n_estimators = 750,\n",
    "    # Step size shrinkage used in update to prevents overfitting\n",
    "    eta=0.05,\n",
    "    # Activates early stopping. Validation metric needs to improve at least once in every early_stopping_rounds round(s) to continue training\n",
    "    early_stopping_rounds=100,\n",
    "    # L2 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_lambda = 2,\n",
    "    # L1 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_alpha = 0,\n",
    "    # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    gamma = 0,\n",
    "    # Specify the learning task and the corresponding learning objective\n",
    "    objective = 'reg:absoluteerror',\n",
    "    # Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit.\n",
    "    max_depth = 12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Wyniki</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvaluator.test(clf, random_day=date(2023, 5, 27))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>Test - XGBoost (Zmienne egzogeniczne/endogeniczne + dni wolne + cyklicznoÅ›Ä‡ + weekendy)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Zmienne</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.Utils import IsEstionianHoliday, IsWeekend\n",
    "\n",
    "features = [\n",
    "    'is_business',\n",
    "    'product_type',\n",
    "    'is_consumption',\n",
    "    'county',\n",
    "    'temperature',\n",
    "    'dewpoint',\n",
    "    'cloudcover_high',\n",
    "    'cloudcover_low',\n",
    "    'cloudcover_mid',\n",
    "    'cloudcover_total',\n",
    "    '10_metre_u_wind_component',\n",
    "    '10_metre_v_wind_component',\n",
    "    'direct_solar_radiation',\n",
    "    'surface_solar_radiation_downwards',\n",
    "    'snowfall',\n",
    "    'total_precipitation',\n",
    "    'installed_capacity',\n",
    "    'elec_price_euros_per_mwh',\n",
    "    'datetime_hour',\n",
    "    'gas_highest_price_per_mwh',\n",
    "    'gas_lowest_price_per_mwh',\n",
    "    'target_2_days_ago',\n",
    "    'target_3_days_ago',\n",
    "    'target_4_days_ago',\n",
    "    'target_5_days_ago',\n",
    "    'target_6_days_ago',\n",
    "    'target_7_days_ago',\n",
    "    'target_8_days_ago',\n",
    "    'target_9_days_ago',\n",
    "    'target_10_days_ago',\n",
    "    'target_11_days_ago',\n",
    "    'target_12_days_ago',\n",
    "    'target_13_days_ago',\n",
    "    'target_14_days_ago',\n",
    "    'is_holiday',\n",
    "    'is_weekend',\n",
    "    'datetime_hour_sin',\n",
    "    'datetime_hour_cos'\n",
    "    ]\n",
    "target_columns = ['target']\n",
    "\n",
    "mergedData = pd.DataFrame(fp.getData(dropNa=True))\n",
    "\n",
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test, X_validation = prepareDataset(features, mergedData)\n",
    "modelEvaluator = EvaluteModel(X_test, y_test, X_validation, county_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Uczenie</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBRegressor (\n",
    "    # Device ordinal, available options are cpu, cuda, and gpu.\n",
    "    device = device, \n",
    "    enable_categorical=True,\n",
    "    # Number of gradient boosted trees\n",
    "    n_estimators = 750,\n",
    "    # Step size shrinkage used in update to prevents overfitting\n",
    "    eta=0.05,\n",
    "    # Activates early stopping. Validation metric needs to improve at least once in every early_stopping_rounds round(s) to continue training\n",
    "    early_stopping_rounds=100,\n",
    "    # L2 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_lambda = 2,\n",
    "    # L1 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_alpha = 0,\n",
    "    # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    gamma = 0,\n",
    "    # Specify the learning task and the corresponding learning objective\n",
    "    objective = 'reg:absoluteerror',\n",
    "    # Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit.\n",
    "    max_depth = 12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Wyniki</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvaluator.test(clf, random_day=date(2023, 5, 27))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>Test - XGBoost (Zmienne egzogeniczne/endogeniczne + dni wolne + cyklicznoÅ›Ä‡ + weekendy + dodatkowe atrybuty)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Zmienne</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.Utils import IsEstionianHoliday, IsWeekend\n",
    "\n",
    "features = [\n",
    "    'is_business',\n",
    "    'product_type',\n",
    "    'is_consumption',\n",
    "    'county',\n",
    "    'temperature',\n",
    "    'dewpoint',\n",
    "    'cloudcover_high',\n",
    "    'cloudcover_low',\n",
    "    'cloudcover_mid',\n",
    "    'cloudcover_total',\n",
    "    '10_metre_u_wind_component',\n",
    "    '10_metre_v_wind_component',\n",
    "    'direct_solar_radiation',\n",
    "    'surface_solar_radiation_downwards',\n",
    "    'snowfall',\n",
    "    'total_precipitation',\n",
    "    'installed_capacity',\n",
    "    'elec_price_euros_per_mwh',\n",
    "    'datetime_hour',\n",
    "    'gas_highest_price_per_mwh',\n",
    "    'gas_lowest_price_per_mwh',\n",
    "    'target_2_days_ago',\n",
    "    'target_3_days_ago',\n",
    "    'target_4_days_ago',\n",
    "    'target_5_days_ago',\n",
    "    'target_6_days_ago',\n",
    "    'target_7_days_ago',\n",
    "    'target_8_days_ago',\n",
    "    'target_9_days_ago',\n",
    "    'target_10_days_ago',\n",
    "    'target_11_days_ago',\n",
    "    'target_12_days_ago',\n",
    "    'target_13_days_ago',\n",
    "    'target_14_days_ago',\n",
    "    'is_holiday',\n",
    "    'is_weekend',\n",
    "    'datetime_hour_sin',\n",
    "    'datetime_hour_cos',\n",
    "    'datetime_day',\n",
    "    'datetime_month',\n",
    "    'datetime_year'\n",
    "    ]\n",
    "target_columns = ['target']\n",
    "\n",
    "mergedData = pd.DataFrame(fp.getData(dropNa=True))\n",
    "\n",
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test, X_validation = prepareDataset(features, mergedData)\n",
    "modelEvaluator = EvaluteModel(X_test, y_test, X_validation, county_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Uczenie</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBRegressor (\n",
    "    # Device ordinal, available options are cpu, cuda, and gpu.\n",
    "    device = device, \n",
    "    enable_categorical=True,\n",
    "    # Number of gradient boosted trees\n",
    "    n_estimators = 750,\n",
    "    # Step size shrinkage used in update to prevents overfitting\n",
    "    eta=0.05,\n",
    "    # Activates early stopping. Validation metric needs to improve at least once in every early_stopping_rounds round(s) to continue training\n",
    "    early_stopping_rounds=100,\n",
    "    # L2 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_lambda = 2,\n",
    "    # L1 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_alpha = 0,\n",
    "    # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    gamma = 0,\n",
    "    # Specify the learning task and the corresponding learning objective\n",
    "    objective = 'reg:absoluteerror',\n",
    "    # Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit.\n",
    "    max_depth = 12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Wyniki</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvaluator.test(clf, random_day=date(2023, 5, 27))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>Test - XGBoost (Zmienne egzogeniczne/endogeniczne + dni wolne + cyklicznoÅ›Ä‡ + weekendy + dodatkowe atrybuty) - problem trendu</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Zmienne</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'is_business',\n",
    "    'product_type',\n",
    "    'is_consumption',\n",
    "    'county',\n",
    "    'temperature',\n",
    "    'dewpoint',\n",
    "    'cloudcover_high',\n",
    "    'cloudcover_low',\n",
    "    'cloudcover_mid',\n",
    "    'cloudcover_total',\n",
    "    '10_metre_u_wind_component',\n",
    "    '10_metre_v_wind_component',\n",
    "    'direct_solar_radiation',\n",
    "    'surface_solar_radiation_downwards',\n",
    "    'snowfall',\n",
    "    'total_precipitation',\n",
    "    'installed_capacity',\n",
    "    'elec_price_euros_per_mwh',\n",
    "    'datetime_hour',\n",
    "    'gas_highest_price_per_mwh',\n",
    "    'gas_lowest_price_per_mwh',\n",
    "    'target_2_days_ago',\n",
    "    'target_3_days_ago',\n",
    "    'is_holiday',\n",
    "    'is_weekend',\n",
    "    'datetime_hour_sin',\n",
    "    'datetime_hour_cos'\n",
    "    ]\n",
    "target_columns = ['target']\n",
    "\n",
    "mergedData = pd.DataFrame(fp.getData(dropNa=True))\n",
    "\n",
    "# Normalization\n",
    "mergedData['target'] = mergedData['target'] / mergedData['installed_capacity']\n",
    "\n",
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test, X_validation = prepareDataset(features, mergedData)\n",
    "\n",
    "modelEvaluator = EvaluteModel(X_test, y_test, X_validation, county_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Uczenie</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBRegressor (\n",
    "    # Device ordinal, available options are cpu, cuda, and gpu.\n",
    "    device = device, \n",
    "    enable_categorical=True,\n",
    "    # Number of gradient boosted trees\n",
    "    n_estimators = 750,\n",
    "    # Step size shrinkage used in update to prevents overfitting\n",
    "    eta=0.05,\n",
    "    # Activates early stopping. Validation metric needs to improve at least once in every early_stopping_rounds round(s) to continue training\n",
    "    early_stopping_rounds=100,\n",
    "    # L2 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_lambda = 2,\n",
    "    # L1 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_alpha = 0,\n",
    "    # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    gamma = 0,\n",
    "    # Specify the learning task and the corresponding learning objective\n",
    "    objective = 'reg:absoluteerror',\n",
    "    # Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit.\n",
    "    max_depth = 12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Wyniki</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvaluator.test(clf, random_day=date(2023, 5, 27), normalization=X_test['installed_capacity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>Najlepszy model + bagging</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Zmienne</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'is_business',\n",
    "    'product_type',\n",
    "    'is_consumption',\n",
    "    'county',\n",
    "    'temperature',\n",
    "    'dewpoint',\n",
    "    'cloudcover_high',\n",
    "    'cloudcover_low',\n",
    "    'cloudcover_mid',\n",
    "    'cloudcover_total',\n",
    "    '10_metre_u_wind_component',\n",
    "    '10_metre_v_wind_component',\n",
    "    'direct_solar_radiation',\n",
    "    'surface_solar_radiation_downwards',\n",
    "    'snowfall',\n",
    "    'total_precipitation',\n",
    "    'installed_capacity',\n",
    "    'elec_price_euros_per_mwh',\n",
    "    'datetime_hour',\n",
    "    'gas_highest_price_per_mwh',\n",
    "    'gas_lowest_price_per_mwh',\n",
    "    'target_2_days_ago',\n",
    "    'target_3_days_ago',\n",
    "    'target_4_days_ago',\n",
    "    'target_5_days_ago',\n",
    "    'target_6_days_ago',\n",
    "    'target_7_days_ago',\n",
    "    'target_8_days_ago',\n",
    "    'target_9_days_ago',\n",
    "    'target_10_days_ago',\n",
    "    'target_11_days_ago',\n",
    "    'target_12_days_ago',\n",
    "    'target_13_days_ago',\n",
    "    'target_14_days_ago',\n",
    "    'is_holiday',\n",
    "    'is_weekend',\n",
    "    'datetime_hour_sin',\n",
    "    'datetime_hour_cos'\n",
    "    ]\n",
    "target_columns = ['target']\n",
    "\n",
    "mergedData = pd.DataFrame(fp.getData(dropNa=True))\n",
    "\n",
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test, X_validation = prepareDataset(features, mergedData)\n",
    "\n",
    "# Normalization\n",
    "y_train['target'] = y_train['target'] / X_train['installed_capacity']\n",
    "\n",
    "modelEvaluator = EvaluteModel(X_test, y_test, X_validation, county_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Uczenie</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "params = {\n",
    "    'device': device, \n",
    "    'enable_categorical': True,\n",
    "    'n_estimators': 750,\n",
    "    'eta': 0.05,\n",
    "    'reg_lambda': 2,\n",
    "    'reg_alpha': 0,\n",
    "    'gamma': 0,\n",
    "    'objective': 'reg:absoluteerror',\n",
    "    'max_depth': 12\n",
    "}\n",
    "\n",
    "model = VotingRegressor([(\n",
    "        f'XGBoost_{i}',\n",
    "        xgb.XGBRegressor(**params, seed = i)\n",
    "    ) for i in range(10)\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Wyniki</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelEvaluator.test(clf, random_day=date(2023, 5, 27), normalization=X_test['installed_capacity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>Najlepszy model + bagging + podziaÅ‚ na konsumpcje/produkcjÄ™</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Zmienne</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'is_business',\n",
    "    'product_type',\n",
    "    'is_consumption',\n",
    "    'county',\n",
    "    'temperature',\n",
    "    'dewpoint',\n",
    "    'cloudcover_high',\n",
    "    'cloudcover_low',\n",
    "    'cloudcover_mid',\n",
    "    'cloudcover_total',\n",
    "    '10_metre_u_wind_component',\n",
    "    '10_metre_v_wind_component',\n",
    "    'direct_solar_radiation',\n",
    "    'surface_solar_radiation_downwards',\n",
    "    'snowfall',\n",
    "    'total_precipitation',\n",
    "    'installed_capacity',\n",
    "    'elec_price_euros_per_mwh',\n",
    "    'datetime_hour',\n",
    "    'gas_highest_price_per_mwh',\n",
    "    'gas_lowest_price_per_mwh',\n",
    "    'target_2_days_ago',\n",
    "    'target_3_days_ago',\n",
    "    'target_4_days_ago',\n",
    "    'target_5_days_ago',\n",
    "    'target_6_days_ago',\n",
    "    'target_7_days_ago',\n",
    "    'target_8_days_ago',\n",
    "    'target_9_days_ago',\n",
    "    'target_10_days_ago',\n",
    "    'target_11_days_ago',\n",
    "    'target_12_days_ago',\n",
    "    'target_13_days_ago',\n",
    "    'target_14_days_ago',\n",
    "    'is_holiday',\n",
    "    'is_weekend',\n",
    "    'datetime_hour_sin',\n",
    "    'datetime_hour_cos'\n",
    "    ]\n",
    "target_columns = ['target']\n",
    "\n",
    "mergedData = pd.DataFrame(fp.getData(dropNa=True))\n",
    "\n",
    "# Normalization\n",
    "mergedData['target'] = mergedData['target'] / mergedData['installed_capacity']\n",
    "\n",
    "consumptionData = mergedData[mergedData.is_consumption == True]\n",
    "productionData = mergedData[mergedData.is_consumption == False]\n",
    "\n",
    "# Splitting into training and testing sets\n",
    "X_train_c, X_test_c, y_train_c, y_test_c, X_validation_c = prepareDataset(features, consumptionData)\n",
    "X_train_p, X_test_p, y_train_p, y_test_p, X_validation_p = prepareDataset(features, productionData)\n",
    "\n",
    "\n",
    "modelEvaluatorConsumption = EvaluteModel(X_test_c, y_test_c, X_validation_c, county_name)\n",
    "modelEvaluatorProduction = EvaluteModel(X_test_p, y_test_p, X_validation_p, county_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Uczenie</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelConsumption = xgb.XGBRegressor (\n",
    "    # Device ordinal, available options are cpu, cuda, and gpu.\n",
    "    device = device, \n",
    "    enable_categorical=True,\n",
    "    # Number of gradient boosted trees\n",
    "    n_estimators = 750,\n",
    "    # Step size shrinkage used in update to prevents overfitting\n",
    "    eta=0.05,\n",
    "    # Activates early stopping. Validation metric needs to improve at least once in every early_stopping_rounds round(s) to continue training\n",
    "    early_stopping_rounds=100,\n",
    "    # L2 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_lambda = 2,\n",
    "    # L1 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_alpha = 0,\n",
    "    # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    gamma = 0,\n",
    "    # Specify the learning task and the corresponding learning objective\n",
    "    objective = 'reg:absoluteerror',\n",
    "    # Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit.\n",
    "    max_depth = 12\n",
    ")\n",
    "\n",
    "modelProduction = xgb.XGBRegressor (\n",
    "    # Device ordinal, available options are cpu, cuda, and gpu.\n",
    "    device = device, \n",
    "    enable_categorical=True,\n",
    "    # Number of gradient boosted trees\n",
    "    n_estimators = 750,\n",
    "    # Step size shrinkage used in update to prevents overfitting\n",
    "    eta=0.05,\n",
    "    # Activates early stopping. Validation metric needs to improve at least once in every early_stopping_rounds round(s) to continue training\n",
    "    early_stopping_rounds=100,\n",
    "    # L2 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_lambda = 2,\n",
    "    # L1 regularization term on weights. Increasing this value will make model more conservative\n",
    "    reg_alpha = 0,\n",
    "    # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    gamma = 0,\n",
    "    # Specify the learning task and the corresponding learning objective\n",
    "    objective = 'reg:absoluteerror',\n",
    "    # Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit.\n",
    "    max_depth = 12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelConsumption.fit(X_train_c, y_train_c, eval_set=[(X_train_c, y_train_c), (X_test_c, y_test_c)], verbose=True)\n",
    "modelProduction.fit(X_train_p, y_train_p, eval_set=[(X_train_p, y_train_p), (X_test_p, y_test_p)], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Wyniki</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvaluatorConsumption.test(modelConsumption, random_day=date(2023, 5, 27), normalization=X_test_c['installed_capacity'])\n",
    "modelEvaluatorProduction.test(modelProduction, random_day=date(2023, 5, 27), normalization=X_test_p['installed_capacity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>Test - RandomForest</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Zmienne</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'is_business',\n",
    "    'product_type',\n",
    "    'is_consumption',\n",
    "    'county',\n",
    "    'temperature',\n",
    "    'dewpoint',\n",
    "    'cloudcover_high',\n",
    "    'cloudcover_low',\n",
    "    'cloudcover_mid',\n",
    "    'cloudcover_total',\n",
    "    '10_metre_u_wind_component',\n",
    "    '10_metre_v_wind_component',\n",
    "    'direct_solar_radiation',\n",
    "    'surface_solar_radiation_downwards',\n",
    "    'snowfall',\n",
    "    'total_precipitation',\n",
    "    'installed_capacity',\n",
    "    'elec_price_euros_per_mwh',\n",
    "    'datetime_hour',\n",
    "    'gas_highest_price_per_mwh',\n",
    "    'gas_lowest_price_per_mwh',\n",
    "    'target_2_days_ago',\n",
    "    'target_3_days_ago',\n",
    "    'is_holiday',\n",
    "    'is_weekend',\n",
    "    'datetime_hour_sin',\n",
    "    'datetime_hour_cos'\n",
    "    ]\n",
    "target_columns = ['target']\n",
    "\n",
    "mergedData = pd.DataFrame(fp.getData(dropNa=True))\n",
    "\n",
    "# Normalization\n",
    "mergedData['target'] = mergedData['target'] / mergedData['installed_capacity']\n",
    "\n",
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test, X_validation = prepareDataset(features, mergedData)\n",
    "\n",
    "modelEvaluator = EvaluteModel(X_test, y_test, X_validation, county_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Uczenie</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "clf = RandomForestRegressor(\n",
    "    # The number of trees in the forest.\n",
    "    n_estimators=80,\n",
    "    # Controls both the randomness of the bootstrapping of the samples used when building trees and the sampling\n",
    "    random_state=0,\n",
    "    # The function to measure the quality of a split. \n",
    "    criterion='squared_error',\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨ <b>Wyniki</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvaluator.test(clf, random_day=date(2023, 5, 27), normalization=X_test['installed_capacity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>Szukanie hiperparametrÃ³w</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'n_estimators': [750, 1000, 1500],\n",
    "        'max_depth': [6, 8, 10],\n",
    "        'eta': [0.1, 0.3, 0.5]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = GridSearchCV(clf, params, verbose=2)\n",
    "\n",
    "#clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.best_params_\n",
    "#{'eta': 0.1, 'max_depth': 10, 'n_estimators': 750}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* eta -> Wybrana wartoÅ›Ä‡ 0.1 - minimalna z przedziaÅ‚u - zmniejszenie zakresu\n",
    "* n_ets -> Wybrana wartoÅ›Ä‡ 750 - minimalna z przedziaÅ‚u - zmniejszenie zakresu\n",
    "* max_depth -> Wybrana wartoÅ›Ä‡ 10 - maksymalna z przedziaÅ‚u - zwiÄ™kszenie zakresu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'n_estimators': [500, 750],\n",
    "        'max_depth': [10, 12, 14],\n",
    "        'eta': [0, 0.05, 0.1]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = GridSearchCV(clf, params, verbose=2)\n",
    "\n",
    "# clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.best_params_\n",
    "# {'eta': 0.05, 'max_depth': 12, 'n_estimators': 750}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'reg_lambda': [0, 1, 2],\n",
    "        'reg_alpha': [0, 1, 2],\n",
    "        'eta': [0, 0.05, 0.1]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = GridSearchCV(clf, params, verbose=2)\n",
    "# clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.best_params_\n",
    "# {'eta': 0.05, 'reg_alpha': 0, 'reg_lambda': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2563eb'>ðŸ”· | <b></span>ZaÅ‚Ä…czanie odpowiedzi</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import enefit\n",
    "#enefit.make_env.func_dict['__called__'] = False\n",
    "#\n",
    "#env = enefit.make_env()\n",
    "#iter_test = env.iter_test()\n",
    "#columns_to_store = ['county', 'is_business', 'product_type', 'is_consumption', 'datetime', 'target', 'data_block_id']\n",
    "#\n",
    "#revealed = None\n",
    "#\n",
    "#for (test_sub, revealed_targets_sub, client_sub, historical_weather_sub,\n",
    "#        forecast_weather_sub, electricity_prices_sub, gas_prices_sub, sample_prediction_sub) in iter_test:\n",
    "#\n",
    "#    # Rename test set to make consistent with train\n",
    "#    test_sub = test_sub.rename(columns = {'prediction_datetime': 'datetime'})\n",
    "#    \n",
    "#    display(test_sub.head(1))\n",
    "#    \n",
    "#    test_sub['data_block_id'] = 0\n",
    "#    client_sub['data_block_id'] = 0\n",
    "#    electricity_prices_sub['data_block_id'] = 0\n",
    "#    gas_prices_sub['data_block_id'] = 0\n",
    "#    forecast_weather_sub['data_block_id'] = 0\n",
    "#\n",
    "#    fp_sub = FeaturesProcessing(\n",
    "#        train = test_sub,\n",
    "#        client = client_sub,\n",
    "#        forecast_weather = forecast_weather_sub,\n",
    "#        gas_prices = gas_prices_sub,\n",
    "#        electricity_prices = electricity_prices_sub,\n",
    "#        weather_station = weather_station,\n",
    "#        submission = True)\n",
    "#    \n",
    "#    \n",
    "#    # Store revealed data\n",
    "#    if revealed is None:\n",
    "#        revealed = revealed_targets_sub\n",
    "#    else:\n",
    "#        revealed = pd.concat([revealed, revealed_targets_sub], ignore_index=True)\n",
    "#    \n",
    "#    # Add revealed data to train\n",
    "#    fp_sub.AddRevealtedTargets(revealed)\n",
    "#    \n",
    "#    # Prediction\n",
    "#    data  = fp_sub.getData()[features]\n",
    "#    display(data.head(1))\n",
    "#    sample_prediction_sub['target'] = clf.predict(data)\n",
    "#    \n",
    "#    env.predict(sample_prediction_sub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
